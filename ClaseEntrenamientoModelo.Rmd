---
title: "Untitled"
author: "Axel Caro"
output: word_document
---

# Carga de librerias

```{r}

library(faraway)
library(tidyverse)
library(skimr)
library(DataExplorer)
library(scales)
library(corrr)

# Librerias para modelamientos

library(glmnet)
library(pls)
library(MLmetrics)

```

# Carga de la base de datos

```{r}
library(readxl)
datos <- read_excel("C:/Users/Aulasmoviles/Downloads/Base Ridge_Lasso.xlsx", sheet = "TO")
head(datos)
```

# Division Train - Test

Se creara una particion de 70% para entrenar y 30% para realizar la prueba del modelo

```{r}

id_train <- sample(1:nrow(datos), size = 0.7 * nrow(datos), replace = F)

datos_train <- datos[id_train, ] # Base de entrenamiento
datos_test <- datos[-id_train, ] # Base de prueba

dim(datos_train); dim(datos_test) # Dimensiones de la nuevas bases

```
# Matrices de entrenamiento y prueba

```{r}
# model.matrix(Variables_Dependiente ~., datos = Nombre_Base)
# ~. : Significa que tomara como covariable todas las columnas que encuentre en la base de datos diferentes a la Variable_Dependiente

x_train <- model.matrix(TO ~., data = datos_train) [,-1]
y_train <- datos_train$TO # Se genera la variable dependiente

x_test <- model.matrix(TO ~., data = datos_test) [,-1]
y_test <- datos_test$TO # Se genera la variable dependiente
```

# Creacion y entrenamiento del modelo

Para obtener un ajuste de regularizacion Lasso se indica el argumento alpha = 1. Si no se especifica el valor se selecciona de un rango automatico.

```{r}

modelo <- glmnet(
  x = x_train, # Matriz de covariables
  y = y_train, # Vector de la variable dependiente
  alpha = 1, # Identifica la regresion lasso
  nlambda = 100,
  standarize = TRUE # Estandarizar las variables
)

```

# Evolucion de los coeficientes en funcion de Lambda

```{r}

regularizacion <- modelo$beta %>%
  as.matrix() %>%
  t() %>%
  as.tibble() %>%
  mutate(lambda = modelo$lambda)

regularizacion <- regularizacion %>%
  pivot_longer(
    cols = !lambda,
    names_to = "Predictor",
    values_to = "Coeficientes"
  )

regularizacion %>%
  ggplot(aes(x = lambda, y = Coeficientes, color = Predictor)) +
geom_line() + 
  scale_x_log10(
    breaks = trans_breaks("log10", function(x) 10 ^x),
    labels = trans_format("log10", math_format(10^.x))
  ) + 
  labs(title = "Coeficiente del modelo en funcion de la regularizacion") +
    theme_bw() + 
    theme(legend.position = "none")
  

```

Como se observa en la grafica anterior, a medida que aumenta el lambda $\lambda$, la regularizacion es mayor, lo cual indica que mas variables independinetes seran excluida del modelo.

# Evolucion del error en funcion de lambda

```{r}

set.seed(123)
cv_error <- cv.glmnet(
  x = x_train,
  y = y_train,
  alpha = 1,
  nfolds = 10,
  type.measure = "mse",
  standardize = TRUE
)

plot(cv_error)

```

# Mejor lambda

```{r}

paste("Mejor lambda encontrado: ", cv_error$lambda.min)

```

# Mejor lambda +1sd

Mayor lambda con el que el test_error no se aleja mas de 1 desviacion estandar del minimo.

```{r}

paste("Mejor lambda encontraro +1 desviacion estandar: ", cv_error$lambda.1se)

```
Se entrenara el modelo empleando el amyor valor de $\lambda$ cuyo error esta a menos de 1 desviacion estandar del minimo encontrado en la validacion cruzada.

```{r}

modelo <- glmnet(
  x = x_train,
  y = y_train,
  alpha = 1,
  lambda = cv_error$lambda.1se,
  standardize = TRUE
)

```

```{r}

df_coeficientes <- coef(modelo) %>%
  as.matrix() %>%
  as_tibble(rownames = "Predictor") %>%
  rename(coeficientes = s0)

df_coeficientes  %>%
  filter(Predictor != ("Intercept")) %>%
  ggplot(aes(x = Predictor, y = coeficientes)) +
  geom_col() + 
  labs(title = "Coeficientes del modelo Ridge") + 
  theme_bw() +
  theme(axis.text = element_text(size = 6, angle = 45))

```


# Predicciones del entrenamiento

```{r}

predicciones_train <- predict(modelo, newx = x_train)
head(predicciones_train,3) # No se recomienda imprimir

```
# MSE de entrenamiento

```{r}
training_test <- mean((predicciones_train - y_train)^2)
paste("Error (mse) de entrenamiento: ", round(training_test,2))

# MAPE
training_test_MAPE <- mean(abs((y_train-predicciones_train)/y_train))
paste("MAPE de entrenamiento %:", 100*round(training_test_MAPE,3))

```
# Predicciones de Test

```{r}

predicciones_test <- predict(modelo, newx = x_test)

```

# MSE y MAPE de test

```{r}
training_test <- mean((predicciones_train - y_train)^2)
paste("Error (mse) de test: ", round(training_test,2))

# MAPE
training_test_MAPE <- mean(abs((y_test-predicciones_test)/y_test))
paste("MAPE de test %:", 100*round(training_test_MAPE,3))
```


